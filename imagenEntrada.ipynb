{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: cuda\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('ALE/SpaceInvaders-v5', render_mode='human')\n",
    "epsilon = 0.99\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Training with:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image():\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "\n",
    "    resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.Grayscale(num_output_channels=1),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "    screen = resize(screen).unsqueeze(0)\n",
    "    return screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def save(self, state, action, next_state, reward):\n",
    "        self.memory.append((state, action, next_state, reward))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(10000)\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    batch = memory.sample(BATCH_SIZE)\n",
    "    ys = []\n",
    "    for b in batch:\n",
    "        (state, action, next_state, reward) = b\n",
    "\n",
    "        if next_state == None: # Es final\n",
    "            y = reward\n",
    "        else:\n",
    "            y = 0\n",
    "            # y = gamma*max<a en A>target_Q(next_state, a)\n",
    "    ys.append(y)\n",
    "        \n",
    "    loss = 0\n",
    "    for i in range(len(batch)):\n",
    "        (state, action, next_state, reward) = batch[i]\n",
    "        # loss += (Q(state, action) - ys[i])^2\n",
    "    # Update Q using the SGD algorithm by minimizing the loss\n",
    "    # Every C steps, copy weights from Q to target_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        \"\"\"Para calcular correctamente la salida, tenemos que linealizarla, esto depende de las dimensiones\n",
    "        de las imagenes de entrada y de los par√°metros introducidos\"\"\"\n",
    "        def conv2d_size_out(size, kernel_size = 3, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    \"\"\"Devuelve un vector con el valor de las acciones posibles\"\"\"\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergio\\AppData\\Local\\Temp\\ipykernel_11596\\2658266957.py:7: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n",
      "d:\\Sergio\\TFM\\TFM_DQN_Atari\\env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "screen = get_image()\n",
    "_, _, screen_height, screen_width = screen.shape\n",
    "\n",
    "red_politica = DQN(screen_height, screen_width, env.action_space.n).to(device)\n",
    "red_objetivo = DQN(screen_height, screen_width, env.action_space.n).to(device)\n",
    "red_objetivo.load_state_dict(red_politica.state_dict())\n",
    "red_objetivo.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(red_politica.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_selection(state):\n",
    "    global epsilon\n",
    "    e = epsilon\n",
    "    epsilon = (epsilon * 99.7)/100\n",
    "    if random.randint(0, 100)/100 < e:\n",
    "        return torch.tensor([[random.randrange(6)]], device=device, dtype=torch.long)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            return  red_politica(state).max(1)[1].view(1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_selection(screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergio\\AppData\\Local\\Temp\\ipykernel_11596\\2658266957.py:7: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n",
      "d:\\Sergio\\TFM\\TFM_DQN_Atari\\env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partida {} acabada 0\n",
      "Partida {} acabada 1\n",
      "Partida {} acabada 2\n",
      "Partida {} acabada 3\n",
      "Partida {} acabada 4\n",
      "Partida {} acabada 5\n",
      "Partida {} acabada 6\n",
      "Partida {} acabada 7\n",
      "Partida {} acabada 8\n",
      "Partida {} acabada 9\n",
      "Partida {} acabada 10\n",
      "Partida {} acabada 11\n",
      "Partida {} acabada 12\n"
     ]
    }
   ],
   "source": [
    "episodios = 100\n",
    "for i in range(episodios):\n",
    "    env.reset()\n",
    "    screen_1 = get_image()\n",
    "    screen_2 = get_image()\n",
    "    estado = screen_2-screen_1\n",
    "\n",
    "    for j in count():\n",
    "        accion = action_selection(estado)\n",
    "        _, recompensa, done, _ = env.step(accion.item())\n",
    "        recompensa = torch.tensor([recompensa], device=device)\n",
    "\n",
    "        screen1 = screen_2\n",
    "        screen2_ = get_image()\n",
    "\n",
    "        if not done:\n",
    "            memory.save(estado, accion, screen_2-screen_1, recompensa)\n",
    "        else:\n",
    "            memory.save(estado, accion, None, recompensa)\n",
    "            break\n",
    "\n",
    "        optimize_model()\n",
    "    print(\"Partida {} acabada\", i)\n",
    "if i % 10 == 0:\n",
    "    red_objetivo.load_state_dict(red_politica.state_dict())\n",
    "\n",
    "\n",
    "torch.save(red_objetivo.state_dict(), \"RedObjetivo.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a381338f764c2e2cde69e871487c18b603a6ed2174a69a63573e476f4f348b8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
